{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "  print(\"Running as a Colab notebook\")\n",
        "  %pip install git+https://github.com/neelnanda-io/Easy-Transformer.git@clean-transformer-demo\n",
        "  # Install another version of node that makes PySvelte work way faster\n",
        "  !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
        "  %pip install git+https://github.com/neelnanda-io/PySvelte.git\n",
        "  %pip install fancy_einsum\n",
        "  %pip install einops\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "  print(\"Running as a Jupyter notebook - intended for development only!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJjJl6bYZckK",
        "outputId": "c3be8d08-c382-4e25-d7b3-e61bfd13e22e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n",
            "Collecting git+https://github.com/neelnanda-io/Easy-Transformer.git@clean-transformer-demo\n",
            "  Cloning https://github.com/neelnanda-io/Easy-Transformer.git (to revision clean-transformer-demo) to /tmp/pip-req-build-8l1fz2lh\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/Easy-Transformer.git /tmp/pip-req-build-8l1fz2lh\n",
            "  Running command git checkout -b clean-transformer-demo --track origin/clean-transformer-demo\n",
            "  Switched to a new branch 'clean-transformer-demo'\n",
            "  Branch 'clean-transformer-demo' set up to track remote branch 'clean-transformer-demo' from 'origin'.\n",
            "  Resolved https://github.com/neelnanda-io/Easy-Transformer.git to commit 1f25219e631aeb478d17075d47274db32c874e88\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting einops (from easy-transformer==0.1.0)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (2.0.1+cu118)\n",
            "Collecting datasets (from easy-transformer==0.1.0)\n",
            "  Downloading datasets-2.14.2-py3-none-any.whl (518 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.9/518.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers (from easy-transformer==0.1.0)\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (4.65.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (1.5.3)\n",
            "Collecting wandb (from easy-transformer==0.1.0)\n",
            "  Downloading wandb-0.15.8-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fancy_einsum (from easy-transformer==0.1.0)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->easy-transformer==0.1.0)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (2.27.1)\n",
            "Collecting xxhash (from datasets->easy-transformer==0.1.0)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->easy-transformer==0.1.0)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (3.8.5)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets->easy-transformer==0.1.0)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->easy-transformer==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->easy-transformer==0.1.0) (2022.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->easy-transformer==0.1.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->easy-transformer==0.1.0) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->easy-transformer==0.1.0) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->easy-transformer==0.1.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers->easy-transformer==0.1.0)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (8.1.6)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->easy-transformer==0.1.0)\n",
            "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->easy-transformer==0.1.0)\n",
            "  Downloading sentry_sdk-1.29.2-py2.py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.6/215.6 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->easy-transformer==0.1.0)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb->easy-transformer==0.1.0)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb->easy-transformer==0.1.0)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->easy-transformer==0.1.0) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (1.3.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->easy-transformer==0.1.0)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->easy-transformer==0.1.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->easy-transformer==0.1.0) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->easy-transformer==0.1.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easy-transformer==0.1.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easy-transformer==0.1.0) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->easy-transformer==0.1.0)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: easy-transformer, pathtools\n",
            "  Building wheel for easy-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for easy-transformer: filename=easy_transformer-0.1.0-py3-none-any.whl size=55599 sha256=e639a27c7bf1985c9879f01e13243ee0b3b4b69a6081924add066c6a0a91c981\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hega3e07/wheels/f0/30/0b/04795723afaae8d7fff47047023153b3e8c47bab26f768cd33\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=c07af9275c854f58974c82b6ca99e5d6d339266477ca171cb38aafa4d205bf58\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built easy-transformer pathtools\n",
            "Installing collected packages: tokenizers, safetensors, pathtools, xxhash, smmap, setproctitle, sentry-sdk, fancy_einsum, einops, docker-pycreds, dill, multiprocess, huggingface-hub, gitdb, transformers, GitPython, wandb, datasets, easy-transformer\n",
            "Successfully installed GitPython-3.1.32 datasets-2.14.2 dill-0.3.7 docker-pycreds-0.4.0 easy-transformer-0.1.0 einops-0.6.1 fancy_einsum-0.0.3 gitdb-4.0.10 huggingface-hub-0.16.4 multiprocess-0.70.15 pathtools-0.1.2 safetensors-0.3.1 sentry-sdk-1.29.2 setproctitle-1.3.2 smmap-5.0.0 tokenizers-0.13.3 transformers-4.31.0 wandb-0.15.8 xxhash-3.3.0\n",
            "\n",
            "## Installing the NodeSource Node.js 16.x repo...\n",
            "\n",
            "\n",
            "## Populating apt-get cache...\n",
            "\n",
            "+ apt-get update\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [977 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [108 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [865 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [833 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,231 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,097 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,159 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,108 kB]\n",
            "Fetched 8,628 kB in 8s (1,017 kB/s)\n",
            "Reading package lists... Done\n",
            "\n",
            "## Confirming \"jammy\" is supported...\n",
            "\n",
            "+ curl -sLf -o /dev/null 'https://deb.nodesource.com/node_16.x/dists/jammy/Release'\n",
            "\n",
            "## Adding the NodeSource signing key to your keyring...\n",
            "\n",
            "+ curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | gpg --dearmor | tee /usr/share/keyrings/nodesource.gpg >/dev/null\n",
            "\n",
            "## Creating apt sources list file for the NodeSource Node.js 16.x repo...\n",
            "\n",
            "+ echo 'deb [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x jammy main' > /etc/apt/sources.list.d/nodesource.list\n",
            "+ echo 'deb-src [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x jammy main' >> /etc/apt/sources.list.d/nodesource.list\n",
            "\n",
            "## Running `apt-get update` for you...\n",
            "\n",
            "+ apt-get update\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 https://deb.nodesource.com/node_16.x jammy InRelease [4,583 B]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://deb.nodesource.com/node_16.x jammy/main amd64 Packages [775 B]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 5,358 B in 4s (1,494 B/s)\n",
            "Reading package lists... Done\n",
            "\n",
            "## Run `\u001b[1msudo apt-get install -y nodejs\u001b[m` to install Node.js 16.x and npm\n",
            "## You may also need development tools to build native addons:\n",
            "     sudo apt-get install gcc g++ make\n",
            "## To install the Yarn package manager, run:\n",
            "     curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | gpg --dearmor | sudo tee /usr/share/keyrings/yarnkey.gpg >/dev/null\n",
            "     echo \"deb [signed-by=/usr/share/keyrings/yarnkey.gpg] https://dl.yarnpkg.com/debian stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\n",
            "     sudo apt-get update && sudo apt-get install yarn\n",
            "\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  nodejs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 27.2 MB of archives.\n",
            "After this operation, 128 MB of additional disk space will be used.\n",
            "Get:1 https://deb.nodesource.com/node_16.x jammy/main amd64 nodejs amd64 16.20.1-deb-1nodesource1 [27.2 MB]\n",
            "Fetched 27.2 MB in 0s (83.4 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package nodejs.\n",
            "(Reading database ... 120500 files and directories currently installed.)\n",
            "Preparing to unpack .../nodejs_16.20.1-deb-1nodesource1_amd64.deb ...\n",
            "Unpacking nodejs (16.20.1-deb-1nodesource1) ...\n",
            "Setting up nodejs (16.20.1-deb-1nodesource1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting git+https://github.com/neelnanda-io/PySvelte.git\n",
            "  Cloning https://github.com/neelnanda-io/PySvelte.git to /tmp/pip-req-build-5fyi37u8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/PySvelte.git /tmp/pip-req-build-5fyi37u8\n",
            "  Resolved https://github.com/neelnanda-io/PySvelte.git to commit 6f5d971a148d40fb7481d400ae74551b37340e83\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (0.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (2.14.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (4.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (4.65.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (1.5.3)\n",
            "Collecting typeguard~=2.0 (from PySvelte==1.0.0)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (2.27.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->PySvelte==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->PySvelte==1.0.0) (2022.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->PySvelte==1.0.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->PySvelte==1.0.0) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->PySvelte==1.0.0) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->PySvelte==1.0.0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->PySvelte==1.0.0) (0.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->PySvelte==1.0.0) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->PySvelte==1.0.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->PySvelte==1.0.0) (1.3.0)\n",
            "Building wheels for collected packages: PySvelte\n",
            "  Building wheel for PySvelte (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PySvelte: filename=PySvelte-1.0.0-py3-none-any.whl size=158306 sha256=4751071261e344f60287eaa45a9d1f6f998306ed73af8157fc4c29d92a9eb9c2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-e9nfr00b/wheels/fa/f6/f2/673ef7aeb78d7503b6e3e42387132822fdc38d3ee283d3e5b4\n",
            "Successfully built PySvelte\n",
            "Installing collected packages: typeguard, PySvelte\n",
            "Successfully installed PySvelte-1.0.0 typeguard-2.13.3\n",
            "Requirement already satisfied: fancy_einsum in /usr/local/lib/python3.10/dist-packages (0.0.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "fRkILM3gDwuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[1,2],[3,4]])\n",
        "print(a)\n",
        "b = a[0,:]\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfQ-HumAD0-u",
        "outputId": "d1ff5712-4bfc-4445-c0f9-acecc50a503c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n",
            "[1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# High-level questions\n",
        "1/ einops & einsum 分别做什么不同的事情\n",
        "\n",
        "`einsum` and `einops` are both tools used for expressing complex array manipulations, but they serve different purposes and have some key differences.\n",
        "\n",
        "### einsum\n",
        "\n",
        "`einsum` stands for \"Einstein summation,\" and it's a function that provides a way to perform operations on multi-dimensional arrays (like matrices or tensors). The name comes from the Einstein summation convention, often used in physics.\n",
        "\n",
        "Here's how it works:\n",
        "\n",
        "- It takes a specified string as its input, detailing the subscript labels for the summation.\n",
        "- It then performs the corresponding element-wise multiplication and summation according to these labels.\n",
        "\n",
        "This function is a part of libraries like NumPy, TensorFlow, and PyTorch, and it allows for a very concise specification of various array operations. For example, matrix multiplication, tensor contraction, and more.\n",
        "\n",
        "### einops\n",
        "\n",
        "这里看的出来还是有挺本质的差别的，einsum is a function while einops is a lib (for many functions?)\n",
        "`einops` is a library that provides a more human-readable way to work with tensor operations. While `einsum` can be powerful, it often ends up being a cryptic and hard-to-read way to specify tensor operations, especially for more complex tasks. `einops` aims to solve this by providing a more intuitive and flexible interface.\n",
        "\n",
        "Some of the key differences between `einops` and `einsum` include:\n",
        "\n",
        "1. **Syntax**: `einops` has a different syntax that is meant to be more readable and consistent. It provides operations like `rearrange`, `reduce`, and `repeat` that make it more explicit what the operation is doing.\n",
        "\n",
        "- Good. I like them.\n",
        "\n",
        "2. **Functionality**: While `einsum` is primarily focused on summation operations involving tensors, `einops` provides a broader set of functionalities for manipulating tensors, including rearranging dimensions, reducing dimensions with various aggregations, and repeating dimensions.\n",
        "\n",
        "- Interesting. 可能最重要的，从功能上区分开二者。einsum主要做summation相关的；einops有rearrange, reduce, and repeat.\n",
        "\n",
        "3. **Compatibility**: `einops` is designed to be compatible with a wide range of deep learning frameworks, such as TensorFlow, PyTorch, and more, aiming to provide a consistent interface across them. - ok\n",
        "\n",
        "4. **Debugging**: `einops` often provides more informative error messages and allows for better debugging experiences.\n",
        "\n",
        "5. **Performance**: `einops` might also offer optimized performance for certain operations, although this can be dependent on the specific task and the underlying framework.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "In summary, `einsum` is a specific function that provides a compact way to perform tensor contractions and other summation operations, following the Einstein summation convention. `einops` is a library that offers a more comprehensive, flexible, and human-readable way to perform tensor operations. It provides a different interface that prioritizes readability and ease of use, while still being powerful and efficient. If you're often working with complex tensor operations, `einops` might be a more user-friendly choice, while `einsum` provides a compact way to express these operations if you're comfortable with its syntax."
      ],
      "metadata": {
        "id": "3f4yFeVRVcPY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnLPZtZOzoXO"
      },
      "outputs": [],
      "source": [
        "# https://einops.rocks/api/reduce/\n",
        "\n",
        "\n",
        ">>> x = np.random.randn(100, 32, 64)\n",
        "\n",
        "# perform max-reduction on the first axis\n",
        ">>> y = reduce(x, 't b c -> b c', 'max') # 同 global average pooling，被省略的字母就是施加某种操作的dimension\n",
        "\n",
        "# same as previous, but with clearer axes meaning\n",
        ">>> y = reduce(x, 'time batch channel -> batch channel', 'max') # 这种可读性更强一点。\n",
        "# 我不确定的地方在于 生成的dimension是不是这样子的：time batch channel -> 1 batch channel\n",
        ">>> x = np.random.randn(10, 20, 30, 40)\n",
        "\n",
        "# 2d max-pooling with kernel size = 2 * 2 for image processing\n",
        ">>> y1 = reduce(x, 'b c (h1 h2) (w1 w2) -> b c h1 w1', 'max', h2=2, w2=2)\n",
        "# 这个可读性其实并不怎么好，h1 w1 应该是y1本身的w & h 但是 h2 w2时max-pooling的dimensions\n",
        "\n",
        "# if one wants to go back to the original height and width, depth-to-space trick can be applied\n",
        ">>> y2 = rearrange(y1, 'b (c h2 w2) h1 w1 -> b c (h1 h2) (w1 w2)', h2=2, w2=2)\n",
        "# interesting. Although the hell this is not readable at all\n",
        ">>> assert parse_shape(x, 'b _ h w') == parse_shape(y2, 'b _ h w')\n",
        "\n",
        "# Adaptive 2d max-pooling to 3 * 4 grid\n",
        ">>> reduce(x, 'b c (h1 h2) (w1 w2) -> b c h1 w1', 'max', h1=3, w1=4).shape\n",
        "(10, 20, 3, 4)\n",
        "# 这应该是reshape在einops里的具体操作：把当下的dimensions、未来的dimensions、操作的种类说清楚，剩下的交给代码自己来做\n",
        "\n",
        "# Global average pooling\n",
        ">>> reduce(x, 'b c h w -> b c', 'mean').shape  # 被省略的字母似乎就是average pooling施影响力的 channels\n",
        "(10, 20)\n",
        "\n",
        "# Subtracting mean over batch for each channel\n",
        ">>> y = x - reduce(x, 'b c h w -> () c () ()', 'mean')\n",
        "# 我猜括号只是为了占位的，而且对于这一行代码，占位挺重要的，因为\"c\"在中间\n",
        "\n",
        "# Subtracting per-image mean for each channel\n",
        ">>> y = x - reduce(x, 'b c h w -> b c () ()', 'mean')\n",
        "# 如果括号只是为了占位的话，以上代码应该同：\n",
        ">>> y = x - reduce(x, 'b c h w -> b c ', 'mean') #NEPTUNE WORK\n",
        "\n",
        "\n",
        "# yes yes 我看懂了这里的代码，per_image mean相对容易，其实是说，每一batch、每一channel (c) 都分别求平均值，然后从x那里减去；\n",
        "# 但\"mean over a batch for each channel\" 是说，要对所有batches的每一个channels求均值\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B7_KmyWrfSCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Einsum practice\n",
        "# https://rockt.github.io/2018/04/30/einsum\n",
        "\n",
        "\n",
        "A = np.random.randn(100,32,24)\n",
        "B = np.random.randn(24,96,100)\n",
        "D = np.random.randn(100,32,24)\n",
        "F = np.random.randn(100,32,1)\n",
        "O = np.random.randn(100,24,64)\n",
        "I = np.ones((2,2,2))\n",
        "\n",
        "print('A:',A.shape)\n",
        "print('B:',B.shape)\n",
        "\n",
        "\n",
        "# matmul\n",
        "C = einsum('a b c, c d e -> a b d e',A,B) # only letters allowed to represent dims (not numbers!)\n",
        "print('C:', C.shape)\n",
        "\n",
        "# element-wise\n",
        "E = einsum('a b c, a b c -> a b c', A,D)\n",
        "print('E:',E.shape)\n",
        "\n",
        "# element-wise, broadcast\n",
        "G = einsum('a b c, a b d -> a b c', A,F)\n",
        "print('G:',G.shape)\n",
        "\n",
        "\n",
        "# element-wise, broadcast, but the other way around\n",
        "H = einsum('a b c, a b d -> a b d', A,F)\n",
        "print('H:',G.shape)  # It looks you can not do broadcast the other way around.\n",
        "\n",
        "# sum\n",
        "# A_sum = einsum('a b c -> ',A)\n",
        "# print('A:',A,'A_sum:',A_sum,'shape of A_sum:',A_sum.shape)\n",
        "# I_sum = einsum('a b c->', I)\n",
        "# print('I_sum:',I_sum,'I_sum shape',I_sum.shape)\n",
        "\n",
        "# B_sum = einsum('a b c->', B)\n",
        "# print('B_sum:',B_sum,'B_sum shape',B_sum.shape)\n",
        "\n",
        "# row sum: sum of every row\n",
        "#A_row_sum = einsum('a b c -> b c',A)\n",
        "# print('A_row_sum shape:', A_row_sum.shape)\n",
        "\n",
        "# Column sum: sum of every column (omit)\n",
        "\n",
        "# Reshape  # transpose 则有固定的顺序\n",
        "B_trans = einsum('a b c-> c b a',B)\n",
        "print('B_trans:',B_trans.shape)\n",
        "\n",
        "J = np.arange(6).reshape(2,3)\n",
        "print('J:',J)\n",
        "\n",
        "# Dot product between two vectors\n",
        "M = N = np.arange(5)\n",
        "MN = einsum('a, a ->',M,N)\n",
        "print('MN & shape',MN,MN.shape)\n",
        "\n",
        "# Dot product between two matrices\n",
        "K = L = np.arange(6).reshape(2,3)\n",
        "KL = einsum('a b, a b ->',K,L)\n",
        "\n",
        "print('KL & shape',KL,KL.shape) # There is no shape for a scalar\n",
        "\n",
        "\n",
        "# Outer product  --> omit, rarely used.\n",
        "\n",
        "# BATCH MATRIX MULTIPLICATION --> Looks very useful in practice. You keep the batch dim but do matmul for other dims\n",
        "\n",
        "AO = einsum('a b c, a c d -> a b d', A,O)\n",
        "print(\"AO:\",AO.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg2zTYQlDv3J",
        "outputId": "0db59e64-2870-47a7-f532-f83d804cbd71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A: (100, 32, 24)\n",
            "B: (24, 96, 100)\n",
            "C: (100, 32, 96, 100)\n",
            "E: (100, 32, 24)\n",
            "G: (100, 32, 24)\n",
            "H: (100, 32, 24)\n",
            "B_trans: (100, 96, 24)\n",
            "J: [[0 1 2]\n",
            " [3 4 5]]\n",
            "MN & shape 30 ()\n",
            "KL & shape 55 ()\n",
            "AO: (100, 32, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention - Aug 3rd. I didn't implement this myself. A bit complicated. Will do so once needed.\n",
        "# Parameters\n",
        "# -- [hidden_dimension]\n",
        "bM, br, w = np.random_tensors([7], num=3, requires_grad=True)\n",
        "# -- [hidden_dimension x hidden_dimension]\n",
        "WY, Wh, Wr, Wt = random_tensors([7, 7], num=4, requires_grad=True)\n",
        "\n",
        "# Single application of attention mechanism\n",
        "def attention(Y, ht, rt1):\n",
        "  # -- [batch_size x hidden_dimension]\n",
        "  tmp = torch.einsum(\"ik,kl->il\", [ht, Wh]) + torch.einsum(\"ik,kl->il\", [rt1, Wr])\n",
        "  Mt = F.tanh(torch.einsum(\"ijk,kl->ijl\", [Y, WY]) + tmp.unsqueeze(1).expand_as(Y) + bM)\n",
        "  # -- [batch_size x sequence_length]\n",
        "  at = F.softmax(torch.einsum(\"ijk,k->ij\", [Mt, w]))\n",
        "  # -- [batch_size x hidden_dimension]\n",
        "  rt = torch.einsum(\"ijk,ij->ik\", [Y, at]) + F.tanh(torch.einsum(\"ij,jk->ik\", [rt1, Wt]) + br)\n",
        "  # -- [batch_size x hidden_dimension], [batch_size x sequence_dimension]\n",
        "  return rt, at\n",
        "\n",
        "# Sampled dummy inputs\n",
        "# -- [batch_size x sequence_length x hidden_dimension]\n",
        "Y = random_tensors([3, 5, 7])\n",
        "# -- [batch_size x hidden_dimension]\n",
        "ht, rt1 = random_tensors([3, 7], num=2)\n",
        "\n",
        "rt, at = attention(Y, ht, rt1)\n",
        "at  # -- print attention weights"
      ],
      "metadata": {
        "id": "-i9dGV7JqYvw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}